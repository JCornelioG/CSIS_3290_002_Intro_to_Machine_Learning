{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a0578b",
   "metadata": {},
   "source": [
    "# Crash Course on Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62194a3",
   "metadata": {},
   "source": [
    "Pandas, not Panda!\n",
    "<img src=\"https://foreignpolicy.com/wp-content/uploads/2014/10/450412342_multiple_pandas_getty_small.jpg?resize=1200,675\" alt=\"pandas\" width=\"400\" height=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a71c8f",
   "metadata": {},
   "source": [
    "## Pandas History\n",
    "\n",
    "Pandas is an open-source Python library providing high-performance, easy-to-use data structures and data analysis tools. The name 'Pandas' is derived from 'Panel Data', an econometrics term for multidimensional structured data sets, as well as a play on the phrase \"Python data analysis\". It is particularly suited for data manipulation and analysis in Python.\n",
    "\n",
    "Pandas is built around data structures called **Series** and **DataFrames**. Data for these collections can be imported from various file formats such as comma-separated values, JSON, Parquet, SQL database tables or queries, and Microsoft Excel.\n",
    "\n",
    "### Key Features \n",
    "\n",
    "- **Efficient Data Manipulation**: Utilizes a fast DataFrame object with integrated indexing for efficient data management.\n",
    "- **Diverse Data Formats**: Supports reading and writing across various formats including CSV, Excel, SQL databases, and HDF5.\n",
    "- **Intelligent Data Alignment**: Automatically aligns data labels in computations, simplifying the handling of missing data.\n",
    "- **Data Reshaping and Pivoting**: Offers flexible options for reshaping and pivoting data sets.\n",
    "- **Advanced Indexing**: Provides intelligent label-based slicing, fancy indexing, and subsetting for large data sets.\n",
    "- **Dynamic Data Structure Modification**: Allows for the insertion and deletion of columns, adapting data structures as needed.\n",
    "- **Powerful Group By Engine**: Supports complex split-apply-combine operations for data aggregation and transformation.\n",
    "- **High-Performance Merging and Joining**: Efficiently merges and joins data sets, maintaining data integrity.\n",
    "- **Hierarchical Axis Indexing**: Facilitates intuitive management of high-dimensional data in a lower-dimensional structure.\n",
    "- **Enhanced Time Series Functionality**: Includes date range generation, frequency conversion, and custom time offsets for comprehensive time series analysis.\n",
    "- **Optimized for Performance**: Critical code paths are written in Cython for high performance.\n",
    "- **Widespread Usage**: Applied across various fields including finance, neuroscience, economics, and more, highlighting its versatility.\n",
    "\n",
    "### Installation using Conda\n",
    "\n",
    "```shell\n",
    "conda install pandas\n",
    "\n",
    "```\n",
    "### Have a taste of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c41e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Optional: Check the version of Pandas\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93994db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating your first DataFrame\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Xander', 'Joanna'],\n",
    "    'Age': [28, 22, 32, 29],\n",
    "    'City': ['New York', 'Paris', 'London', 'Berlin']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290325bd",
   "metadata": {},
   "source": [
    "## Panda Series\n",
    "\n",
    "A Series is a 1-dimensional data structure built on top of NumPy's array. Unlike in NumPy, each data point has an associated *label*. The collection of these labels is called an *index*. A series can be thought of as a column in a table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbba310",
   "metadata": {},
   "source": [
    "### Creating Series\n",
    "\n",
    "Series can be created from various data types including lists, dictionaries, and even scalars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ef612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Series from a list\n",
    "series_from_list = pd.Series([1, 3, 5, 7, 9])\n",
    "print(\"Series from list:\\n\")\n",
    "print(series_from_list)\n",
    "\n",
    "# Creating Series from a list and Specifying the index\n",
    "\n",
    "series_from_list_with_index = pd.Series([1, 3, 5, 7, 9],index=['a', 'b', 'c', 'd','e'])  # Each data point has a corresponding label\n",
    "print(\"\\nSeries from list with specified index:\\n\")\n",
    "print(series_from_list_with_index)\n",
    "\n",
    "# Creating Series from a dictionary\n",
    "series_from_dict = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
    "print(\"\\nSeries from dictionary:\\n\")\n",
    "print(series_from_dict)\n",
    "\n",
    "# Creating Series from a scalar\n",
    "series_from_scalar = pd.Series(5, index=[0, 1, 2, 3])\n",
    "print(\"\\nSeries from scalar:\\n\")\n",
    "print(series_from_scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdd02f",
   "metadata": {},
   "source": [
    "### Indexing and Selection in Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00a6bd",
   "metadata": {},
   "source": [
    "Elements in a Series can be accessed using various methods including index labels and integer location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing elements by index\n",
    "print(\"Value at index 'b':\\n\")\n",
    "print(series_from_dict['b'])\n",
    "\n",
    "\n",
    "# Slicing a Series\n",
    "print(\"\\nFirst three elements:\\n\")\n",
    "print(series_from_list[:3])\n",
    "\n",
    "\n",
    "# Conditional selection (Filtering)\n",
    "print(\"\\nElements greater than 5:\\n\")\n",
    "print(series_from_list[series_from_list > 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df85ce",
   "metadata": {},
   "source": [
    "### Modifying Series Values\n",
    "\n",
    "Values in a Pandas Series can be modified directly via indexing or using methods like `replace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd58b2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a Series\n",
    "s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "# Modifying a single value\n",
    "s['a'] = 15\n",
    "print(\"After modifying 'a':\\n\")\n",
    "print(s)\n",
    "\n",
    "# Modifying multiple values\n",
    "s[['c', 'd']] = 100\n",
    "print(\"\\nAfter modifying 'c' and 'd':\\n\")\n",
    "print(s)\n",
    "\n",
    "# Replacing value using replace()\n",
    "s.replace(100, 75, inplace=True)\n",
    "print(\"\\nAfter replacing 100 with 75:\\n\")\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faebc75",
   "metadata": {},
   "source": [
    "### Modifying Series Indices\n",
    "The index of a Pandas Series can be changed by directly assigning a new list of index labels to the `.index` attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the entire index\n",
    "s.index = ['v', 'w', 'x', 'y', 'z']\n",
    "print(\"Series with new indices:\\n\")\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b65f56",
   "metadata": {},
   "source": [
    "### Applying Functions to Series\n",
    "\n",
    "Functions can be applied to Series using methods like `map`, `apply`, and vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a45419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using map to apply a function\n",
    "s_mapped = s.map(lambda x: x ** 2)\n",
    "print(\"Series after applying map function (square):\\n\")\n",
    "print(s_mapped)\n",
    "\n",
    "# Using apply for more complex functions\n",
    "def format_number(x):\n",
    "    return f\"${x:.2f}\"\n",
    "\n",
    "s_formatted = s.apply(format_number)\n",
    "print(\"\\nSeries after formatting numbers:\\n\")\n",
    "print(s_formatted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884074f8",
   "metadata": {},
   "source": [
    "### Operations on Series\n",
    "\n",
    "Pandas supports both element-wise operations and bulk mathematical operations that can be applied directly to Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec739def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant to a Series\n",
    "print(\"Add 5 to each element:\\n\")\n",
    "print(series_from_list + 5)\n",
    "\n",
    "\n",
    "# Multiplying Series elements\n",
    "print(\"\\nMultiply each element by 2:\\n\")\n",
    "print(series_from_list * 2)\n",
    "\n",
    "# Calculating cumulative sum\n",
    "print(\"\\nCumulative sum of the series:\\n\")\n",
    "print(series_from_list.cumsum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980417e0",
   "metadata": {},
   "source": [
    "### Handling Missing Data in Series\n",
    "\n",
    "Pandas provides convenient methods to handle missing data, allowing for easy filtering out or filling of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350dbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series with missing values\n",
    "series_with_na = pd.Series([1, None, 3, None, 5])\n",
    "\n",
    "# Handling missing values by filling them\n",
    "print(\"Fill missing values with 0:\\n\")\n",
    "print(series_with_na.fillna(0))\n",
    "\n",
    "# Dropping missing values\n",
    "print(\"\\nDrop missing values:\\n\")\n",
    "print(series_with_na.dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70046d6",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "\n",
    "A DataFrame is a 2-dimensional tabular data structure of rows and columns, similar to a spreadsheet, and analogous to a Python dictionary mapping column names (keys) to Series (values). It is essentially a collection of Series (each row) objects that share the same index. DataFrames can be concatenated together or \"merged\" on columns or indices in a manner similar to joins in SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1e473",
   "metadata": {},
   "source": [
    "### Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple DataFrame from a dictionary\n",
    "data = {'Name': ['John', 'Anna', 'Xander', 'Joanna'],\n",
    "        'Age': [28, 22, 32, 29],\n",
    "        'City': ['New York', 'Paris', 'London', 'Berlin']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b25a9",
   "metadata": {},
   "source": [
    "#### Creating DataFrame with Custom Column Names and Custom Index\n",
    "Custom indices and column names can make your DataFrame easier to read and manipulate. They allow you to access data more intuitively and make your code cleaner and more understandable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c7dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a simple DataFrame from a 2d list\n",
    "\n",
    "# Data for the DataFrame\n",
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# Specifying custom column names\n",
    "columns = ['First', 'Second', 'Third']\n",
    "df_custom_columns = pd.DataFrame(data, columns=columns)\n",
    "print(\"DataFrame with Custom Column Names:\\n\", df_custom_columns)\n",
    "\n",
    "\n",
    "# Specifying custom index\n",
    "index = ['Row1', 'Row2', 'Row3']\n",
    "df_custom_index = pd.DataFrame(data, columns=columns, index=index)\n",
    "print(\"DataFrame with Custom Index:\\n\", df_custom_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c99ab7",
   "metadata": {},
   "source": [
    "#### Modifying Existing DataFrame Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4401f957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Existing DataFrame\n",
    "df_existing = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Setting a new index\n",
    "new_index = ['x', 'y', 'z']\n",
    "df_existing.index = new_index\n",
    "print(\"Modified Index in DataFrame:\\n\", df_existing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f676769",
   "metadata": {},
   "source": [
    "#### Use one of the DataFrame columns as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using column as index\n",
    "df_set_index = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Cindy'],\n",
    "    'Age': [25, 26, 27]\n",
    "})\n",
    "\n",
    "df_set_index.set_index('Name', inplace=True)\n",
    "print(\"DataFrame Using Name as Index:\\n\", df_set_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2179349",
   "metadata": {},
   "source": [
    "### Updating Pandas DataFrame Index and Column Names\n",
    "\n",
    "Updating the index and column names in a DataFrame can help make the data more readable and easier to work with, especially when merging datasets or performing complex data manipulations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26820fd3",
   "metadata": {},
   "source": [
    "#### Renaming Coluns in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "df_update = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Renaming columns\n",
    "df_update.rename(columns={'A': 'Alpha', 'B': 'Beta'}, inplace=True)\n",
    "print(\"DataFrame with Renamed Columns:\\n\", df_update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51f727",
   "metadata": {},
   "source": [
    "#### Updating DataFrame Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting new index labels\n",
    "df_update.index = ['one', 'two', 'three']\n",
    "print(\"DataFrame with Updated Index:\\n\", df_update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9eb0fb",
   "metadata": {},
   "source": [
    "#### Resetting the DataFrame index to the default integer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8649a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index\n",
    "df_reset = df_update.reset_index(drop=True)\n",
    "print(\"DataFrame with Reset Index:\\n\", df_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14126203",
   "metadata": {},
   "source": [
    "### Access data in a DataFrame\n",
    "\n",
    "Accessing data efficiently is crucial for performing data analysis tasks in Pandas. Various methods like direct indexing, slicing, and attribute methods (`loc` and `iloc`) are available to retrieve data from a DataFrame.\n",
    "\n",
    "In the code example below, note the conditions under which the stop index is excluded and when it is included in the slicing syntax start:stop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7530d",
   "metadata": {},
   "source": [
    "####  Direct Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8cf689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple DataFrame from a dictionary\n",
    "data = {'Name': ['John', 'Anna', 'Xander', 'Joanna'],\n",
    "        'Age': [28, 22, 32, 29],\n",
    "        'City': ['New York', 'Paris', 'London', 'Berlin']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da86b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Direct indexing to access a column as a Panda Series\n",
    "print(\"Accessing the 'Name' column:\\n\", df['Name'])\n",
    "\n",
    "# Direct indexing to access a column as a Panda DataFrame\n",
    "print(\"Accessing the 'Name' column:\\n\", df[['Name']])\n",
    "\n",
    "# Direct indexing to access multiple columns as a Panda DataFrame \n",
    "print(\"Accessing the 'Name' column:\\n\", df[['Name', 'Age']])\n",
    "\n",
    "# Wrong Codes, the symbol : cannot be used for columns in direct indexing\n",
    "# print(\"Accessing the 'Name' column:\\n\", df[['Name': 'Age']])\n",
    "\n",
    "\n",
    "# Slicing to access rows, notice here column 2 is excluded\n",
    "print(\"\\nAccessing the first two rows:\\n\", df[0:2])\n",
    "\n",
    "# Wrong Codes. Without :, 1 here will be considered to be columns names\n",
    "# print(\"\\nAccessing the first two rows:\\n\", df[1])\n",
    "\n",
    "df.index = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# Slicing to access rows, notice here column 'c' is NOT excluded\n",
    "print(\"\\nAccessing the first two rows:\\n\", df['a':'c'])\n",
    "\n",
    "# reset the index\n",
    "df.index = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af034f",
   "metadata": {},
   "source": [
    "#### Using loc for Label-Based Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using loc to access a specific row by index label\n",
    "print(\"Data in the second row using loc:\\n\", df.loc[1])\n",
    "\n",
    "# Using loc to access a range of rows and specific columns\n",
    "print(\"\\nData from rows 1 to 3 and 'Name' and 'Age' columns:\\n\", df.loc[1:3, ['Name', 'Age']])\n",
    "\n",
    "# Note that contrary to usual python slices, both the start and the stop are included for loc (not for iloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59c9c1",
   "metadata": {},
   "source": [
    "#### Using iloc for Position-Based Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using iloc to access a specific row by integer position\n",
    "print(\"Data in the third row using iloc:\\n\", df.iloc[2])\n",
    "\n",
    "# Using iloc to access a range of rows and columns by positions\n",
    "print(\"\\nData from rows 0 to 2 and first two columns using iloc:\\n\", df.iloc[0:3, 0:2])\n",
    "\n",
    "# in iloc, the stop index is also excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459a3e1",
   "metadata": {},
   "source": [
    "To summarize, in Pandas, when slicing data frames, the stop index is typically excluded, following Python's usual indexing conventions. However, there are specific situations in pandas where the behavior might differ, particularly when using labels instead of integer positions:\n",
    "\n",
    "- Integer Position-Based Indexing (iloc): The stop index is excluded. This means if you slice with iloc[start:stop], it includes the rows or columns at position start up to but not including stop.\n",
    "\n",
    "- Label-Based Indexing (loc): The stop index is included. When using loc[start:stop], it includes the rows or columns labeled from start to stop, inclusive. This is different from typical Python slicing because it is label-based rather than position-based.\n",
    "\n",
    "-  Direct indexing primarily follows the Python list-like behavior of exclusive stop indices, but the specifics can vary depending on whether you are indexing by label or by position:\n",
    "\n",
    "    - Positional Indexing: If you directly index using integer slices, such as df[start:stop], the behavior is similar to Python lists where the stop index is excluded. This slice will include rows from the position start up to, but not including, stop.\n",
    "\n",
    "    - Label-Based Direct Indexing: When directly indexing with label slices (e.g., df['start_label':'stop_label']), pandas includes both the start and stop labels in the result. This means all rows or columns from the start label up to and including the stop label are included. This behavior is particularly useful when working with DataFrames that have a meaningful index (like dates or other categories).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0835460c",
   "metadata": {},
   "source": [
    "#### Conditional Access with Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing to filter data\n",
    "print(\"Rows where Age is greater than 25:\\n\", df[df['Age'] > 25])\n",
    "\n",
    "# Combining conditions\n",
    "print(\"\\nRows where Age is greater than 25 and City is New York:\\n\", df[(df['Age'] > 25) & (df['City'] == 'New York')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75902f52",
   "metadata": {},
   "source": [
    "### Modifying DataFrame Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c81d69",
   "metadata": {},
   "source": [
    "DataFrame structure can be modified by adding, deleting, or modifying columns and rows using appropriate methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "df['Salary'] = ['100', '200', '150', '300']\n",
    "print(\"After adding Salary column:\\n\", df)\n",
    "\n",
    "# Deleting a column\n",
    "df.drop('City', axis=1, inplace=True)\n",
    "print(\"\\nAfter deleting City column:\\n\", df)\n",
    "\n",
    "# Modifying row data\n",
    "df.loc[1, 'Age'] = 25\n",
    "print(\"\\nAfter modifying Age of row with index 1:\\n\", df)\n",
    "\n",
    "# Adding a new row\n",
    "df.loc[len(df)] = ['Jimmy', 30, 200]\n",
    "print(\"\\nAfter adding a new row about Jimmy\\n\", df)\n",
    "\n",
    "# There used to be a method called .append, but it is removed now in the latest Pandas version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff012c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_row = {'Name':'Adam', 'Age':35, 'Salary':200}\n",
    "df = df.append(new_row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d210301",
   "metadata": {},
   "source": [
    "### Working with Missing Data\n",
    "\n",
    "Pandas provides methods for detecting, removing, and filling missing values in a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with missing values\n",
    "df_with_missing = pd.DataFrame({'A': [1, 2, None, 4, 5]})\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"Missing values:\\n\")\n",
    "print(df_with_missing.isna())\n",
    "\n",
    "# Filling missing values\n",
    "df_with_missing.fillna(0, inplace=True)\n",
    "print(\"\\nAfter filling missing values:\\n\")\n",
    "print(df_with_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfac113",
   "metadata": {},
   "source": [
    "### Inspecting a DataFrame\n",
    "Before diving deep into data analysis, it's crucial to first understand the basic structure of your DataFrame, including its index, columns, and a preview of its data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the first few rows\n",
    "print(\"First 3 rows of the DataFrame:\\n\", df.head(3))\n",
    "\n",
    "# Viewing the last few rows\n",
    "print(\"\\nLast 2 rows of the DataFrame:\\n\", df.tail(2))\n",
    "\n",
    "# Checking the number of rows and columns\n",
    "print(\"Number of rows and columns:\", df.shape)\n",
    "\n",
    "# Displaying the total number of elements\n",
    "print(\"Total number of elements in the DataFrame:\", df.size)\n",
    "\n",
    "# Displaying index information\n",
    "print(\"Index of the DataFrame:\", df.index)\n",
    "\n",
    "# Displaying column names\n",
    "print(\"Column names of the DataFrame:\", df.columns)\n",
    "\n",
    "# Getting summary information about the DataFrame\n",
    "print(\"Summary info of the DataFrame:\")\n",
    "df.info()\n",
    "\n",
    "# Generating descriptive statistics\n",
    "print(\"Descriptive statistics of the DataFrame:\\n\", df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e1cbc",
   "metadata": {},
   "source": [
    "### Reading CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b44081",
   "metadata": {},
   "source": [
    "CSV (Comma-Separated Values) files are a common data format used in data analysis. Pandas provides simple and flexible tools to read this type of file and convert it into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a basic CSV file\n",
    "df = pd.read_csv('path/to/your/file.csv')\n",
    "print(\"Data from CSV file:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbb8ac",
   "metadata": {},
   "source": [
    "#### Specifying Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading CSV without headers and specifying column names\n",
    "df_no_header = pd.read_csv('path/to/your/file.csv', header=None, names=['Name', 'Age', 'City'])\n",
    "print(\"CSV data with custom column names:\\n\", df_no_header.head())11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8674486",
   "metadata": {},
   "source": [
    "### Combining DataFrames\n",
    "\n",
    "Combining two DataFrames in Pandas can be done using various methods, depending on the specific requirements of your data and the kind of merging or concatenation you need. Here are some of the most commonly used methods to combine two DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1'], 'B': ['B0', 'B1']})\n",
    "df2 = pd.DataFrame({'A': ['A2', 'A3'], 'B': ['B2', 'B3']})\n",
    "df3 = pd.DataFrame({'C': ['C0', 'C1'], 'D': ['C2', 'C3']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26c807",
   "metadata": {},
   "source": [
    "#### Concatenation\n",
    "\n",
    "`concat` method is useful for appending DataFrames vertically (stacking rows, `axis=0`, along the Index direction) or horizontally (stacking columns, `axis=1`, along the column direction). This function is handy when you have DataFrames with the same columns and want to combine them into a single DataFrame, or if you want to add the columns of one DataFrame to another where the rows align."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e7df7",
   "metadata": {},
   "source": [
    "##### Vertical Concatenation (Stacking Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can concatenate vertically when the columns are the same\n",
    "\n",
    "result1 = pd.concat([df1, df2], axis=0)\n",
    "print(result1)\n",
    "\n",
    "result2 = pd.concat([df1, df2], ignore_index = True, axis=0)\n",
    "print(result2)\n",
    "\n",
    "result3 = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05153285",
   "metadata": {},
   "source": [
    "What if we have concat DataFrames that have *different columns*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511e274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result3 = pd.concat([df1, df3], axis=0).reset_index(drop=True)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118da06",
   "metadata": {},
   "source": [
    "The issue arises because the column names weren't aligned. Consequently, when we concatenated the new dataframe, it preserved all six columns but inserted NaN values in places where there were no corresponding values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5883aa7",
   "metadata": {},
   "source": [
    "##### Horizontal Concatenation (Stacking Columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62394450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can concatenate horizontally when the indices are the same\n",
    "\n",
    "result3 = pd.concat([df1, df2], axis=1)\n",
    "print(result3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f963e",
   "metadata": {},
   "source": [
    "#### Merging\n",
    "\n",
    "merge is used for combining DataFrames based on common columns or indices, similar to SQL joins. It allows for inner, outer, left, and right joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a663b",
   "metadata": {},
   "source": [
    "##### Inner Merge\n",
    "This operation will only include rows that have matching values in both DataFrames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another sample DataFrame\n",
    "df4 = pd.DataFrame({'A': ['A0', 'A3'], 'C': ['C0', 'C3']})\n",
    "\n",
    "# Merge DataFrames on column 'A'\n",
    "result = pd.merge(df1, df4, on='A')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525431a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index for join\n",
    "df1_indexed = df1.set_index('A')\n",
    "df4_indexed = df4.set_index('A')\n",
    "print(df1_indexed)\n",
    "print(df4_indexed)\n",
    "\n",
    "# Join on the indices\n",
    "result = df1_indexed.join(df4_indexed, how='left')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed600238",
   "metadata": {},
   "source": [
    "#### Required Reading for this section:\n",
    "\n",
    "https://pandas.pydata.org/docs/user_guide/merging.html\n",
    "\n",
    "https://realpython.com/pandas-merge-join-and-concat/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4a71e",
   "metadata": {},
   "source": [
    "### Groupby and Aggregation\n",
    "\n",
    "The `groupby` operation involves splitting the data into groups based on some criteria, applying a function to each group independently, and combining the results. This process is particularly useful for aggregating or summarizing data in complex datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ef62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Groupby Operations\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Company': ['Google', 'Google', 'Microsoft', 'Microsoft', 'Facebook', 'Facebook'],\n",
    "    'Employee': ['Sam', 'Charlie', 'Amy', 'Vanessa', 'Carl', 'Sarah'],\n",
    "    'Sales': [200, 120, 340, 124, 243, 350]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by 'Company'\n",
    "group_by_company = df.groupby('Company')\n",
    "\n",
    "# Sum of sales by company\n",
    "print(\"Sum of Sales by Company:\\n\", group_by_company.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8490a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple aggregation functions\n",
    "\n",
    "print(\"Statistics of Sales by Company:\\n\", group_by_company['Sales'].agg(['sum', 'mean', 'min', 'max']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation function to calculate range\n",
    "\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "print(\"Range of Sales by Company:\\n\", group_by_company['Sales'].agg(range_func))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6022a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a 'Year' column to the data\n",
    "df['Year'] = [2020, 2021, 2020, 2021, 2020, 2021]\n",
    "\n",
    "# Grouping by both 'Company' and 'Year'\n",
    "group_by_company_year = df.groupby(['Company', 'Year'])\n",
    "\n",
    "# Average sales by company and year\n",
    "print(\"Average Sales by Company and Year:\\n\", group_by_company_year['Sales'].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
